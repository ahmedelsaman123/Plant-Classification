{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plant Disease Detection Group Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning - UFCFAS-15-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GroupMembers\n",
    "#### Ahmed Elsaman - 21072727\n",
    "#### Hatim Shaherawla - 21054059\n",
    "#### Tommy Diclaudio - 21035734"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                             # Importing pandas library for data manipulation\n",
    "import pathlib                                   # Importing pathlib library for file path manipulation\n",
    "import tensorflow as tf                          # Importing TensorFlow library for deep learning\n",
    "import matplotlib.pyplot as plt                  # Importing matplotlib library for data visualization\n",
    "import numpy as np                               # Importing NumPy library for numerical computation\n",
    "import os                                        # Importing os library for operating system related tasks\n",
    "import PIL                                       # Importing Python Imaging Library for image processing\n",
    "import glob                                      # Importing glob library for file path pattern matching\n",
    "from tensorflow import keras                     # Importing keras module from TensorFlow for building deep learning models\n",
    "from keras import layers                         # Importing layers module from keras for building deep learning models\n",
    "from keras.models import Sequential              # Importing Sequential model from keras for building deep learning models\n",
    "from keras.utils import image_dataset_from_directory  # Importing image_dataset_from_directory function from keras for loading images\n",
    "from keras.preprocessing.image import ImageDataGenerator  # Importing ImageDataGenerator class from keras for data augmentation\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Flatten, Dense, Dropout, BatchNormalization  # Importing different types of layers from keras for building deep learning models\n",
    "from keras.losses import SparseCategoricalCrossentropy  # Importing SparseCategoricalCrossentropy loss function from keras\n",
    "from keras.regularizers import l2                 # Importing l2 regularizer from keras for regularization\n",
    "import os                                        # Importing os library for operating system related tasks\n",
    "\n",
    "%matplotlib inline                               # Magic command for displaying plots inline in Jupyter Notebook\n",
    "from glob import glob                            # Importing glob library for file path pattern matching\n",
    "import seaborn as sns                            # Importing seaborn library for data visualization\n",
    "from PIL import Image                            # Importing Python Imaging Library for image processing\n",
    "np.random.seed(11)                               # Setting seed for reproducibility\n",
    "from sklearn.preprocessing import StandardScaler # Importing StandardScaler class from scikit-learn for scaling data\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV # Importing different modules from scikit-learn for model evaluation and tuning\n",
    "from sklearn.metrics import accuracy_score       # Importing accuracy_score function from scikit-learn for computing model accuracy\n",
    "import itertools                                 # Importing itertools library for various combinatorial functions\n",
    "\n",
    "import keras                                     # Importing keras library for deep learning\n",
    "from keras.utils.np_utils import to_categorical # Importing to_categorical function from keras for one-hot encoding of target variable\n",
    "from keras.models import Sequential, Model       # Importing different modules from keras for building deep learning models\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D # Importing different types of layers from keras for building deep learning models\n",
    "from keras import backend as K                   # Importing backend module from keras for backend-specific functions\n",
    "from keras.layers import BatchNormalization     # Importing BatchNormalization layer from keras for normalization\n",
    "from keras.optimizers import Adam, RMSprop       # Importing Adam and RMSprop optimizers from keras for model optimization\n",
    "from keras.preprocessing.image import ImageDataGenerator  # Importing ImageDataGenerator class from keras for data augmentation\n",
    "from keras.callbacks import ReduceLROnPlateau    # Importing ReduceLROnPlateau class from keras for learning rate scheduling\n",
    "from keras.wrappers.scikit_learn import KerasClassifier  # Importing KerasClassifier wrapper from scikit-learn for using keras models with scikit-learn API\n",
    "from keras.applications.inception_v3 import InceptionV3   # Importing InceptionV3 pre-trained model from keras\n",
    "from keras import backend as K\n",
    "import random  # for generating random numbers\n",
    "import urllib.request  # for downloading images from URLs\n",
    "import matplotlib.image as mpimg  # for loading images as arrays\n",
    "\n",
    "from skimage.filters import rank, threshold_otsu  # for applying image filters\n",
    "from skimage import io  # for reading and displaying images\n",
    "from skimage.color import rgb2gray  # for converting images to grayscale\n",
    "from sklearn.cluster import KMeans  # for applying k-means clustering algorithm\n",
    "from skimage.morphology import closing, square, disk  # for applying morphological operations on images\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the path to the original dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_dir = pathlib.Path(\"archive/plantvillage dataset/color\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gettng list of directories in data directory and print it, then print the amount of directories found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_path_train = os.listdir(data_dir)   \n",
    "print (dataset_path_train)\n",
    "print(\"Amount of classes found: \", len(dataset_path_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sets the batch size for the image data generator and the image height and width for the images in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning with Fine-Tuning using VGG16 for Multi-Class Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code uses the Keras library to prepare the data for the image classification task by applying data augmentation techniques. It then loads a pre-trained VGG16 model and freezes all its layers except for the last fully connected layers. A new fully connected layer is added and then the model is compiled. Finally, the last 10 layers of the model are unfrozen for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import VGG16\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Transfer learning\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "predictions = Dense(38, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Fine-tuning\n",
    "for layer in model.layers[-10:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "optimizer = SGD(learning_rate=0.001, momentum=0.9)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=1,\n",
    "    validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Get the predicted labels for the test set\n",
    "test_pred = model.predict(test_generator)\n",
    "test_pred_labels = np.argmax(test_pred, axis=1)\n",
    "\n",
    "# Get the true labels for the test set\n",
    "test_true_labels = test_generator.classes\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(test_true_labels, test_pred_labels)\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code sample performs image prediction using a trained TensorFlow model, and displays the predicted and actual class labels along with their respective confidence levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import expand_dims\n",
    "\n",
    "labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "def predict(model, img):\n",
    "    \n",
    "    img_array = img.numpy()\n",
    "    img_array = expand_dims(img_array, 0)\n",
    "\n",
    "    predictions = model.predict(img_array)\n",
    "\n",
    "    predicted_class = labels[np.argmax(predictions[0])]\n",
    "    confidence = round(np.max(predictions[0]) * 100, 2)\n",
    "    \n",
    "    return predicted_class, confidence\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "for images, lbs in val_ds.take(1):\n",
    "    for i in range(12):\n",
    "        \n",
    "        plt.subplot(4, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint32\"))\n",
    "        \n",
    "        predicted_class, confidence = predict(model, images[i])\n",
    "        actual_class = labels[lbs[i]] \n",
    "        \n",
    "        title = f\"Actual: {actual_class},\\n Predicted: {predicted_class}.\\n Confidence: {confidence}%\"\n",
    "        if actual_class == predicted_class:\n",
    "            plt.title(title, color=\"green\")\n",
    "        else:\n",
    "            plt.title(title, color=\"red\")\n",
    "        \n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "        plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('ml': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d70042a30536c6705cd685ac2da9e393b465a353b934e1086abbf8476aa4359"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
